{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "torch (Python 3.8)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Pytorch_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqkUt16k9b7"
      },
      "source": [
        "!pip install albumentations\n",
        "!pip install --upgrade albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTodLFKSiX25"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data as data_utils\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For image-keypoints data augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensor\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-l0bWiJlASS",
        "outputId": "ec1bd9e7-555b-4f2e-ea9b-bd7534dadd59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNEsGUDAiX2_"
      },
      "source": [
        "# Prefix data directory #각자 데이터가 있는 경로 넣기 #local 폴더 하나 만들기\n",
        "prefix_dir = '/content/drive/MyDrive/1. open'\n",
        "\n",
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "# to the ImageFolder structure\n",
        "train_dir = f'{prefix_dir}/train_imgs'\n",
        "\n",
        "# Models to choose from torchvision\n",
        "model_name = 'resnet'\n",
        "model_ver = '18'\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 48\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 64\n",
        "\n",
        "# Number of epochs and earlystop to train for\n",
        "num_epochs = 60\n",
        "\n",
        "num_splits = 10\n",
        "num_earlystop = 10\n",
        "\n",
        "# Iput size for resize imgae\n",
        "input_w = 150\n",
        "input_h = 150\n",
        "\n",
        "# Learning rate for optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "# when True we only update the reshaped layer params\n",
        "feature_extract = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "pVDZOX4liX3A",
        "outputId": "de8d42aa-b415-40fa-8d45-218b28427a8a"
      },
      "source": [
        "df = pd.read_csv(f'{prefix_dir}/train_df.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>nose_x</th>\n",
              "      <th>nose_y</th>\n",
              "      <th>left_eye_x</th>\n",
              "      <th>left_eye_y</th>\n",
              "      <th>right_eye_x</th>\n",
              "      <th>right_eye_y</th>\n",
              "      <th>left_ear_x</th>\n",
              "      <th>left_ear_y</th>\n",
              "      <th>right_ear_x</th>\n",
              "      <th>right_ear_y</th>\n",
              "      <th>left_shoulder_x</th>\n",
              "      <th>left_shoulder_y</th>\n",
              "      <th>right_shoulder_x</th>\n",
              "      <th>right_shoulder_y</th>\n",
              "      <th>left_elbow_x</th>\n",
              "      <th>left_elbow_y</th>\n",
              "      <th>right_elbow_x</th>\n",
              "      <th>right_elbow_y</th>\n",
              "      <th>left_wrist_x</th>\n",
              "      <th>left_wrist_y</th>\n",
              "      <th>right_wrist_x</th>\n",
              "      <th>right_wrist_y</th>\n",
              "      <th>left_hip_x</th>\n",
              "      <th>left_hip_y</th>\n",
              "      <th>right_hip_x</th>\n",
              "      <th>right_hip_y</th>\n",
              "      <th>left_knee_x</th>\n",
              "      <th>left_knee_y</th>\n",
              "      <th>right_knee_x</th>\n",
              "      <th>right_knee_y</th>\n",
              "      <th>left_ankle_x</th>\n",
              "      <th>left_ankle_y</th>\n",
              "      <th>right_ankle_x</th>\n",
              "      <th>right_ankle_y</th>\n",
              "      <th>neck_x</th>\n",
              "      <th>neck_y</th>\n",
              "      <th>left_palm_x</th>\n",
              "      <th>left_palm_y</th>\n",
              "      <th>right_palm_x</th>\n",
              "      <th>right_palm_y</th>\n",
              "      <th>spine2(back)_x</th>\n",
              "      <th>spine2(back)_y</th>\n",
              "      <th>spine1(waist)_x</th>\n",
              "      <th>spine1(waist)_y</th>\n",
              "      <th>left_instep_x</th>\n",
              "      <th>left_instep_y</th>\n",
              "      <th>right_instep_x</th>\n",
              "      <th>right_instep_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001-1-1-01-Z17_A-0000001.jpg</td>\n",
              "      <td>1046.389631</td>\n",
              "      <td>344.757881</td>\n",
              "      <td>1041.655294</td>\n",
              "      <td>329.820225</td>\n",
              "      <td>1059.429507</td>\n",
              "      <td>334.484230</td>\n",
              "      <td>1020.117796</td>\n",
              "      <td>338.890539</td>\n",
              "      <td>1048.000000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>992.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>1054.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>956.000000</td>\n",
              "      <td>368.000000</td>\n",
              "      <td>1134.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>1003.497242</td>\n",
              "      <td>327.640085</td>\n",
              "      <td>1078.000000</td>\n",
              "      <td>341.00000</td>\n",
              "      <td>999.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>1046.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>995.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>1054.0</td>\n",
              "      <td>698.0</td>\n",
              "      <td>983.000000</td>\n",
              "      <td>820.000000</td>\n",
              "      <td>1042.0</td>\n",
              "      <td>829.0</td>\n",
              "      <td>1019.107277</td>\n",
              "      <td>373.766222</td>\n",
              "      <td>1013.137360</td>\n",
              "      <td>316.311695</td>\n",
              "      <td>1067.000000</td>\n",
              "      <td>335.000000</td>\n",
              "      <td>1019.484230</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>1026.515770</td>\n",
              "      <td>514.054730</td>\n",
              "      <td>998.578836</td>\n",
              "      <td>826.718013</td>\n",
              "      <td>1063.204067</td>\n",
              "      <td>838.827465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001-1-1-01-Z17_A-0000003.jpg</td>\n",
              "      <td>1069.850679</td>\n",
              "      <td>340.711494</td>\n",
              "      <td>1058.608552</td>\n",
              "      <td>324.593690</td>\n",
              "      <td>1075.242111</td>\n",
              "      <td>325.593690</td>\n",
              "      <td>1041.422997</td>\n",
              "      <td>331.694815</td>\n",
              "      <td>1065.593682</td>\n",
              "      <td>333.968459</td>\n",
              "      <td>1010.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>386.0</td>\n",
              "      <td>974.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>1144.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>1004.000000</td>\n",
              "      <td>346.000000</td>\n",
              "      <td>1094.000000</td>\n",
              "      <td>326.00000</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>557.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>583.0</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>697.0</td>\n",
              "      <td>1003.843781</td>\n",
              "      <td>678.797029</td>\n",
              "      <td>1042.0</td>\n",
              "      <td>829.0</td>\n",
              "      <td>1047.279440</td>\n",
              "      <td>362.031898</td>\n",
              "      <td>1017.383112</td>\n",
              "      <td>332.890539</td>\n",
              "      <td>1081.187380</td>\n",
              "      <td>323.000000</td>\n",
              "      <td>1046.953248</td>\n",
              "      <td>454.062706</td>\n",
              "      <td>1058.766231</td>\n",
              "      <td>508.797029</td>\n",
              "      <td>1002.265676</td>\n",
              "      <td>699.062706</td>\n",
              "      <td>1066.376234</td>\n",
              "      <td>841.499445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001-1-1-01-Z17_A-0000005.jpg</td>\n",
              "      <td>1084.475902</td>\n",
              "      <td>337.000008</td>\n",
              "      <td>1078.717997</td>\n",
              "      <td>323.757889</td>\n",
              "      <td>1095.648412</td>\n",
              "      <td>325.242119</td>\n",
              "      <td>1061.039884</td>\n",
              "      <td>329.351571</td>\n",
              "      <td>1086.461032</td>\n",
              "      <td>334.109461</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>1083.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>984.000000</td>\n",
              "      <td>362.000000</td>\n",
              "      <td>1163.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>1027.507419</td>\n",
              "      <td>327.383120</td>\n",
              "      <td>1111.000000</td>\n",
              "      <td>340.00000</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1061.0</td>\n",
              "      <td>556.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>674.0</td>\n",
              "      <td>1070.0</td>\n",
              "      <td>696.0</td>\n",
              "      <td>987.703151</td>\n",
              "      <td>788.867342</td>\n",
              "      <td>1044.0</td>\n",
              "      <td>826.0</td>\n",
              "      <td>1063.029716</td>\n",
              "      <td>358.679953</td>\n",
              "      <td>1042.374777</td>\n",
              "      <td>319.031541</td>\n",
              "      <td>1101.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>1044.538960</td>\n",
              "      <td>442.054730</td>\n",
              "      <td>1052.844144</td>\n",
              "      <td>495.890539</td>\n",
              "      <td>989.437847</td>\n",
              "      <td>808.757889</td>\n",
              "      <td>1066.071417</td>\n",
              "      <td>841.749554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001-1-1-01-Z17_A-0000007.jpg</td>\n",
              "      <td>1042.320047</td>\n",
              "      <td>361.452689</td>\n",
              "      <td>1037.907194</td>\n",
              "      <td>344.117804</td>\n",
              "      <td>1050.328382</td>\n",
              "      <td>353.913729</td>\n",
              "      <td>1016.844144</td>\n",
              "      <td>340.913737</td>\n",
              "      <td>1042.164191</td>\n",
              "      <td>359.351579</td>\n",
              "      <td>968.0</td>\n",
              "      <td>392.0</td>\n",
              "      <td>1010.0</td>\n",
              "      <td>411.0</td>\n",
              "      <td>941.812612</td>\n",
              "      <td>339.703151</td>\n",
              "      <td>1109.0</td>\n",
              "      <td>441.0</td>\n",
              "      <td>971.654931</td>\n",
              "      <td>328.648429</td>\n",
              "      <td>1066.812604</td>\n",
              "      <td>383.40631</td>\n",
              "      <td>972.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>559.0</td>\n",
              "      <td>991.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>1110.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>991.406302</td>\n",
              "      <td>816.132650</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>591.0</td>\n",
              "      <td>1007.302983</td>\n",
              "      <td>374.179405</td>\n",
              "      <td>981.842327</td>\n",
              "      <td>329.109461</td>\n",
              "      <td>1057.406318</td>\n",
              "      <td>372.461040</td>\n",
              "      <td>982.937294</td>\n",
              "      <td>458.109462</td>\n",
              "      <td>990.375124</td>\n",
              "      <td>507.624866</td>\n",
              "      <td>1001.305177</td>\n",
              "      <td>829.233767</td>\n",
              "      <td>1159.516499</td>\n",
              "      <td>599.389997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001-1-1-01-Z17_A-0000009.jpg</td>\n",
              "      <td>1058.046395</td>\n",
              "      <td>343.164191</td>\n",
              "      <td>1046.717997</td>\n",
              "      <td>331.703163</td>\n",
              "      <td>1058.132650</td>\n",
              "      <td>331.781079</td>\n",
              "      <td>1031.258806</td>\n",
              "      <td>338.593690</td>\n",
              "      <td>1049.812620</td>\n",
              "      <td>338.187380</td>\n",
              "      <td>997.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>1054.0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>961.000000</td>\n",
              "      <td>423.000000</td>\n",
              "      <td>1132.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>988.676303</td>\n",
              "      <td>357.688297</td>\n",
              "      <td>1080.000000</td>\n",
              "      <td>337.00000</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>567.0</td>\n",
              "      <td>1043.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>673.0</td>\n",
              "      <td>1059.0</td>\n",
              "      <td>701.0</td>\n",
              "      <td>998.406302</td>\n",
              "      <td>784.570501</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>827.0</td>\n",
              "      <td>1036.318945</td>\n",
              "      <td>366.195727</td>\n",
              "      <td>999.777421</td>\n",
              "      <td>349.829291</td>\n",
              "      <td>1069.648429</td>\n",
              "      <td>334.109461</td>\n",
              "      <td>1024.843791</td>\n",
              "      <td>453.687572</td>\n",
              "      <td>1034.391088</td>\n",
              "      <td>510.843791</td>\n",
              "      <td>998.625231</td>\n",
              "      <td>805.218921</td>\n",
              "      <td>1059.625956</td>\n",
              "      <td>839.765102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          image       nose_x  ...  right_instep_x  right_instep_y\n",
              "0  001-1-1-01-Z17_A-0000001.jpg  1046.389631  ...     1063.204067      838.827465\n",
              "1  001-1-1-01-Z17_A-0000003.jpg  1069.850679  ...     1066.376234      841.499445\n",
              "2  001-1-1-01-Z17_A-0000005.jpg  1084.475902  ...     1066.071417      841.749554\n",
              "3  001-1-1-01-Z17_A-0000007.jpg  1042.320047  ...     1159.516499      599.389997\n",
              "4  001-1-1-01-Z17_A-0000009.jpg  1058.046395  ...     1059.625956      839.765102\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQy7B_kAiX3A"
      },
      "source": [
        "imgs = df.iloc[:, 0].to_numpy()\n",
        "motions = df.iloc[:, 1:]\n",
        "columns = motions.columns.to_list()[::2]\n",
        "class_labels = [label.replace('_x', '').replace('_y', '') for label in columns]\n",
        "keypoints = []\n",
        "for motion in motions.to_numpy():\n",
        "    a_keypoints = []\n",
        "    for i in range(0, motion.shape[0], 2):\n",
        "        a_keypoints.append((float(motion[i]), float(motion[i+1])))\n",
        "    keypoints.append(a_keypoints)\n",
        "keypoints = np.array(keypoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXM5NMfaiX3A"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, earlystop=0, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "    \n",
        "    val_acc_history = []\n",
        "    val_loss_history = []\n",
        "    earlystop_value = 0\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0\n",
        "    best_loss = 999999999\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_since = time.time()\n",
        "        if earlystop and earlystop_value >= earlystop:\n",
        "            break\n",
        "\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs.float(), labels.float())\n",
        "                        loss2 = criterion(aux_outputs.float(), labels.float())\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs.float(), labels.float())\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                # for regression\n",
        "                running_corrects += torch.sum(outputs == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            epoch_time_elapsed = time.time() - epoch_since\n",
        "            print('{} ({}) Loss: {:.4f} Acc: {:.4f} Elapsed time: {:.0f}m {:.0f}s'.format(\n",
        "                phase, len(dataloaders[phase].dataset), epoch_loss, epoch_acc, epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
        "            #neptune.log_metric(f'{phase}_loss', epoch_loss)\n",
        "            #neptune.log_metric(f'{phase}_acc', epoch_acc)\n",
        "            \n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    earlystop_value = 0\n",
        "                else:\n",
        "                    earlystop_value += 1\n",
        "                val_loss_history.append(epoch_loss)\n",
        "                val_acc_history.append(epoch_acc)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training and Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best validation Acc: {:4f}\\n'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, {'acc': val_acc_history, 'loss': val_loss_history}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0jkviPciX3B"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc0rcJbiiX3C",
        "outputId": "7fafdb32-38f7-45d3-aee2-21f12b000440"
      },
      "source": [
        "def initialize_model(model_name, model_ver, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    # variables is model specific.\n",
        "    model_ft = getattr(models, f'{model_name}{model_ver}')(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    return model_ft\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft = initialize_model(model_name, model_ver, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=48, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcjuAcFriX3D"
      },
      "source": [
        "# Data augmentation and normalization for training with Albumentations\n",
        "A_transforms = {\n",
        "    'train':\n",
        "        A.Compose([\n",
        "            A.Resize(input_h, input_w, always_apply=True),\n",
        "            A.OneOf([A.HorizontalFlip(p=1),\n",
        "                     A.RandomRotate90(p=1),\n",
        "                     A.VerticalFlip(p=1)            \n",
        "            ], p=0.5),\n",
        "            A.OneOf([A.MotionBlur(p=1),\n",
        "                     A.GaussNoise(p=1)                 \n",
        "            ], p=0.5),\n",
        "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "            ToTensor()\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n",
        "    \n",
        "    'val':\n",
        "        A.Compose([\n",
        "            A.Resize(input_h, input_w, always_apply=True),\n",
        "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "            ToTensor()\n",
        "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels'], remove_invisible=True, angle_in_degrees=True)),\n",
        "    \n",
        "    'test':\n",
        "        A.Compose([\n",
        "            A.Resize(input_h, input_w, always_apply=True),\n",
        "            A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "            ToTensor()\n",
        "        ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NdygVXGiX3D"
      },
      "source": [
        "class Dataset(data_utils.Dataset):\n",
        "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
        "    def __init__(self, data_dir, imgs, keypoints, phase, class_labels=None, data_transforms=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.imgs = imgs\n",
        "        self.keypoints = keypoints\n",
        "        self.phase = phase\n",
        "        self.class_labels = class_labels\n",
        "        self.data_transforms = data_transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Read an image with OpenCV\n",
        "        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n",
        "        keypoints = self.keypoints[idx]\n",
        "    \n",
        "        if self.data_transforms:\n",
        "            augmented = self.data_transforms[self.phase](image=img, keypoints=keypoints, class_labels=self.class_labels)\n",
        "            img = augmented['image']\n",
        "            keypoints = augmented['keypoints']\n",
        "        keypoints = np.array(keypoints).flatten()\n",
        "\n",
        "        return img, keypoints\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "#train 넘 길어서 끝나면 찾아봤는데 한 셀 끝나면 삡소리 나는 코드래ㅎ\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R69VWOeYiX3E",
        "outputId": "8750c00e-3ec6-4250-e858-0dad91436b02"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "since = time.time()\n",
        "X_train, X_val, y_train, y_val = train_test_split(imgs, keypoints, test_size=1/num_splits, random_state=42)\n",
        "train_data = Dataset(train_dir, X_train, y_train, data_transforms=A_transforms, class_labels=class_labels, phase='train')\n",
        "val_data = Dataset(train_dir, X_val, y_val, data_transforms=A_transforms, class_labels=class_labels, phase='val')\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = data_utils.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hists = train_model(\n",
        "    model_ft, dataloaders, criterion, optimizer_ft,\n",
        "    num_epochs=num_epochs, earlystop=num_earlystop, is_inception=(model_name==\"inception\"))\n",
        "torch.save(model_ft.state_dict(), f'{prefix_dir}/local/baseline_{model_name}{model_ver}.pt')\n",
        "time_elapsed = time.time() - since\n",
        "print('Elapsed time: {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "----------\n",
            "train (3775) Loss: 817.5892 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 256.2412 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 2/60\n",
            "----------\n",
            "train (3775) Loss: 254.3940 Acc: 0.0000 Elapsed time: 1m 45s\n",
            "val (420) Loss: 377.2808 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 3/60\n",
            "----------\n",
            "train (3775) Loss: 165.5187 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 153.9246 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 4/60\n",
            "----------\n",
            "train (3775) Loss: 130.4168 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 171.0567 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 5/60\n",
            "----------\n",
            "train (3775) Loss: 90.9904 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 79.8386 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 6/60\n",
            "----------\n",
            "train (3775) Loss: 74.8638 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 60.6093 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 7/60\n",
            "----------\n",
            "train (3775) Loss: 66.6540 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 62.5706 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 8/60\n",
            "----------\n",
            "train (3775) Loss: 63.5390 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 54.2665 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 9/60\n",
            "----------\n",
            "train (3775) Loss: 56.5909 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 46.3448 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 10/60\n",
            "----------\n",
            "train (3775) Loss: 53.0826 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 47.1574 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 11/60\n",
            "----------\n",
            "train (3775) Loss: 52.0865 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 38.0191 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 12/60\n",
            "----------\n",
            "train (3775) Loss: 47.2643 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 36.8616 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 13/60\n",
            "----------\n",
            "train (3775) Loss: 43.2115 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 30.2172 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 14/60\n",
            "----------\n",
            "train (3775) Loss: 39.5055 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 28.0710 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 15/60\n",
            "----------\n",
            "train (3775) Loss: 38.8962 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 25.9401 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 16/60\n",
            "----------\n",
            "train (3775) Loss: 36.3578 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 35.2621 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 17/60\n",
            "----------\n",
            "train (3775) Loss: 34.5339 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 21.7867 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 18/60\n",
            "----------\n",
            "train (3775) Loss: 31.9113 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 21.3628 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 19/60\n",
            "----------\n",
            "train (3775) Loss: 29.9078 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 19.8712 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 20/60\n",
            "----------\n",
            "train (3775) Loss: 27.0494 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 19.6411 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 21/60\n",
            "----------\n",
            "train (3775) Loss: 28.2510 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 18.8288 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 22/60\n",
            "----------\n",
            "train (3775) Loss: 26.4345 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 17.3852 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 23/60\n",
            "----------\n",
            "train (3775) Loss: 28.6366 Acc: 0.0000 Elapsed time: 1m 46s\n",
            "val (420) Loss: 20.9163 Acc: 0.0000 Elapsed time: 1m 56s\n",
            "\n",
            "Epoch 24/60\n",
            "----------\n",
            "train (3775) Loss: 25.8288 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 17.1829 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 25/60\n",
            "----------\n",
            "train (3775) Loss: 25.9118 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 16.6516 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 26/60\n",
            "----------\n",
            "train (3775) Loss: 25.0216 Acc: 0.0000 Elapsed time: 1m 45s\n",
            "val (420) Loss: 15.4129 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 27/60\n",
            "----------\n",
            "train (3775) Loss: 23.6868 Acc: 0.0000 Elapsed time: 1m 46s\n",
            "val (420) Loss: 22.4147 Acc: 0.0000 Elapsed time: 1m 57s\n",
            "\n",
            "Epoch 28/60\n",
            "----------\n",
            "train (3775) Loss: 24.5082 Acc: 0.0000 Elapsed time: 1m 46s\n",
            "val (420) Loss: 15.4743 Acc: 0.0000 Elapsed time: 1m 57s\n",
            "\n",
            "Epoch 29/60\n",
            "----------\n",
            "train (3775) Loss: 20.1450 Acc: 0.0000 Elapsed time: 1m 46s\n",
            "val (420) Loss: 15.9285 Acc: 0.0000 Elapsed time: 1m 57s\n",
            "\n",
            "Epoch 30/60\n",
            "----------\n",
            "train (3775) Loss: 20.7060 Acc: 0.0000 Elapsed time: 1m 46s\n",
            "val (420) Loss: 15.8785 Acc: 0.0000 Elapsed time: 1m 57s\n",
            "\n",
            "Epoch 31/60\n",
            "----------\n",
            "train (3775) Loss: 21.5640 Acc: 0.0000 Elapsed time: 1m 45s\n",
            "val (420) Loss: 13.6667 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 32/60\n",
            "----------\n",
            "train (3775) Loss: 21.8787 Acc: 0.0000 Elapsed time: 1m 47s\n",
            "val (420) Loss: 14.2344 Acc: 0.0000 Elapsed time: 1m 58s\n",
            "\n",
            "Epoch 33/60\n",
            "----------\n",
            "train (3775) Loss: 19.9328 Acc: 0.0000 Elapsed time: 1m 46s\n",
            "val (420) Loss: 13.3975 Acc: 0.0000 Elapsed time: 1m 57s\n",
            "\n",
            "Epoch 34/60\n",
            "----------\n",
            "train (3775) Loss: 21.3696 Acc: 0.0003 Elapsed time: 1m 43s\n",
            "val (420) Loss: 18.9114 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 35/60\n",
            "----------\n",
            "train (3775) Loss: 20.5707 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 17.7351 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 36/60\n",
            "----------\n",
            "train (3775) Loss: 19.4088 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 14.7029 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 37/60\n",
            "----------\n",
            "train (3775) Loss: 19.1667 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 13.6559 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 38/60\n",
            "----------\n",
            "train (3775) Loss: 20.3032 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 14.4077 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 39/60\n",
            "----------\n",
            "train (3775) Loss: 18.0629 Acc: 0.0000 Elapsed time: 1m 45s\n",
            "val (420) Loss: 11.6001 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 40/60\n",
            "----------\n",
            "train (3775) Loss: 18.8321 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 15.8745 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 41/60\n",
            "----------\n",
            "train (3775) Loss: 17.9598 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 10.6482 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 42/60\n",
            "----------\n",
            "train (3775) Loss: 17.5545 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 12.7185 Acc: 0.0000 Elapsed time: 1m 54s\n",
            "\n",
            "Epoch 43/60\n",
            "----------\n",
            "train (3775) Loss: 17.9655 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 12.9986 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 44/60\n",
            "----------\n",
            "train (3775) Loss: 18.7485 Acc: 0.0003 Elapsed time: 1m 43s\n",
            "val (420) Loss: 12.3912 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 45/60\n",
            "----------\n",
            "train (3775) Loss: 18.0533 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 10.4273 Acc: 0.0000 Elapsed time: 1m 52s\n",
            "\n",
            "Epoch 46/60\n",
            "----------\n",
            "train (3775) Loss: 17.9263 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 12.9426 Acc: 0.0000 Elapsed time: 1m 52s\n",
            "\n",
            "Epoch 47/60\n",
            "----------\n",
            "train (3775) Loss: 17.3070 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 14.3562 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 48/60\n",
            "----------\n",
            "train (3775) Loss: 15.5391 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 11.2560 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 49/60\n",
            "----------\n",
            "train (3775) Loss: 17.3440 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 12.0706 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 50/60\n",
            "----------\n",
            "train (3775) Loss: 16.4954 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 10.8415 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 51/60\n",
            "----------\n",
            "train (3775) Loss: 15.0196 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 11.4132 Acc: 0.0000 Elapsed time: 1m 52s\n",
            "\n",
            "Epoch 52/60\n",
            "----------\n",
            "train (3775) Loss: 15.3637 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 10.0147 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 53/60\n",
            "----------\n",
            "train (3775) Loss: 15.1303 Acc: 0.0000 Elapsed time: 1m 43s\n",
            "val (420) Loss: 9.3009 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 54/60\n",
            "----------\n",
            "train (3775) Loss: 13.9439 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 9.7632 Acc: 0.0000 Elapsed time: 1m 52s\n",
            "\n",
            "Epoch 55/60\n",
            "----------\n",
            "train (3775) Loss: 14.6113 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 11.6283 Acc: 0.0000 Elapsed time: 1m 53s\n",
            "\n",
            "Epoch 56/60\n",
            "----------\n",
            "train (3775) Loss: 15.7283 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 14.3784 Acc: 0.0000 Elapsed time: 1m 52s\n",
            "\n",
            "Epoch 57/60\n",
            "----------\n",
            "train (3775) Loss: 15.4824 Acc: 0.0000 Elapsed time: 1m 42s\n",
            "val (420) Loss: 9.6876 Acc: 0.0000 Elapsed time: 1m 52s\n",
            "\n",
            "Epoch 58/60\n",
            "----------\n",
            "train (3775) Loss: 13.0084 Acc: 0.0000 Elapsed time: 1m 44s\n",
            "val (420) Loss: 9.9665 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 59/60\n",
            "----------\n",
            "train (3775) Loss: 13.4743 Acc: 0.0000 Elapsed time: 1m 45s\n",
            "val (420) Loss: 9.2156 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Epoch 60/60\n",
            "----------\n",
            "train (3775) Loss: 14.0467 Acc: 0.0000 Elapsed time: 1m 45s\n",
            "val (420) Loss: 12.0989 Acc: 0.0000 Elapsed time: 1m 55s\n",
            "\n",
            "Training and Validation complete in 114m 6s\n",
            "Best validation Acc: 0.000000\n",
            "\n",
            "Elapsed time: 114m 6s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbuPCvpeiX3E",
        "outputId": "e3697818-3f88-49e7-eeb6-bd49d410a76b"
      },
      "source": [
        "model_ft.load_state_dict(torch.load(f'{prefix_dir}/local/baseline_{model_name}{model_ver}.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RxBTP0xiX3F"
      },
      "source": [
        "test_dir = f'{prefix_dir}/test_imgs'\n",
        "test_imgs = os.listdir(test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJnlriWqiX3F"
      },
      "source": [
        "class TestDataset(data_utils.Dataset):\n",
        "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
        "    def __init__(self, data_dir, imgs, phase, data_transforms=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.imgs = imgs\n",
        "        self.phase = phase\n",
        "        self.data_transforms = data_transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.imgs[idx]\n",
        "        # Read an image with OpenCV\n",
        "        img = cv2.imread(os.path.join(self.data_dir, self.imgs[idx]))\n",
        "\n",
        "        if self.data_transforms:\n",
        "            augmented = self.data_transforms[self.phase](image=img)\n",
        "            img = augmented['image']\n",
        "        return filename, img\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "test_data = TestDataset(test_dir, test_imgs, data_transforms=A_transforms, phase='test')\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=batch_size * 4, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aizNKmZjiX3F"
      },
      "source": [
        "all_predictions = []\n",
        "files = []\n",
        "with torch.no_grad():\n",
        "    for filenames, inputs in test_loader:\n",
        "        predictions = list(model_ft(inputs.to(device)).cpu().numpy())\n",
        "        files.extend(filenames)\n",
        "        for prediction in predictions:\n",
        "            all_predictions.append(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10bpggJ8iX3G"
      },
      "source": [
        "all_predictions = np.array(all_predictions)\n",
        "for i in range(all_predictions.shape[0]):\n",
        "    all_predictions[i, [2*j for j in range(num_classes//2)]] /= input_w / 1920\n",
        "    all_predictions[i, [2*j + 1 for j in range(num_classes//2)]] /= input_h / 1080"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "4-IsTajeiX3G",
        "outputId": "73ed76f3-bed5-4179-efc6-ba5e7d989766"
      },
      "source": [
        "df_sub = pd.read_csv(f'{prefix_dir}/sample_submission.csv')\n",
        "df = pd.DataFrame(columns=df_sub.columns)\n",
        "df['image'] = files\n",
        "df.iloc[:, 1:] = all_predictions\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>nose_x</th>\n",
              "      <th>nose_y</th>\n",
              "      <th>left_eye_x</th>\n",
              "      <th>left_eye_y</th>\n",
              "      <th>right_eye_x</th>\n",
              "      <th>right_eye_y</th>\n",
              "      <th>left_ear_x</th>\n",
              "      <th>left_ear_y</th>\n",
              "      <th>right_ear_x</th>\n",
              "      <th>right_ear_y</th>\n",
              "      <th>left_shoulder_x</th>\n",
              "      <th>left_shoulder_y</th>\n",
              "      <th>right_shoulder_x</th>\n",
              "      <th>right_shoulder_y</th>\n",
              "      <th>left_elbow_x</th>\n",
              "      <th>left_elbow_y</th>\n",
              "      <th>right_elbow_x</th>\n",
              "      <th>right_elbow_y</th>\n",
              "      <th>left_wrist_x</th>\n",
              "      <th>left_wrist_y</th>\n",
              "      <th>right_wrist_x</th>\n",
              "      <th>right_wrist_y</th>\n",
              "      <th>left_hip_x</th>\n",
              "      <th>left_hip_y</th>\n",
              "      <th>right_hip_x</th>\n",
              "      <th>right_hip_y</th>\n",
              "      <th>left_knee_x</th>\n",
              "      <th>left_knee_y</th>\n",
              "      <th>right_knee_x</th>\n",
              "      <th>right_knee_y</th>\n",
              "      <th>left_ankle_x</th>\n",
              "      <th>left_ankle_y</th>\n",
              "      <th>right_ankle_x</th>\n",
              "      <th>right_ankle_y</th>\n",
              "      <th>neck_x</th>\n",
              "      <th>neck_y</th>\n",
              "      <th>left_palm_x</th>\n",
              "      <th>left_palm_y</th>\n",
              "      <th>right_palm_x</th>\n",
              "      <th>right_palm_y</th>\n",
              "      <th>spine2(back)_x</th>\n",
              "      <th>spine2(back)_y</th>\n",
              "      <th>spine1(waist)_x</th>\n",
              "      <th>spine1(waist)_y</th>\n",
              "      <th>left_instep_x</th>\n",
              "      <th>left_instep_y</th>\n",
              "      <th>right_instep_x</th>\n",
              "      <th>right_instep_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>714-3-5-35-Z94_D-0000001.jpg</td>\n",
              "      <td>983.371</td>\n",
              "      <td>373.967</td>\n",
              "      <td>1017.8</td>\n",
              "      <td>361.027</td>\n",
              "      <td>997.629</td>\n",
              "      <td>361.597</td>\n",
              "      <td>1042.76</td>\n",
              "      <td>371.309</td>\n",
              "      <td>1001.18</td>\n",
              "      <td>368.643</td>\n",
              "      <td>1078.17</td>\n",
              "      <td>440.561</td>\n",
              "      <td>973.326</td>\n",
              "      <td>434.984</td>\n",
              "      <td>1116.9</td>\n",
              "      <td>486.492</td>\n",
              "      <td>937.062</td>\n",
              "      <td>474.596</td>\n",
              "      <td>1062.76</td>\n",
              "      <td>486.525</td>\n",
              "      <td>919.911</td>\n",
              "      <td>484.848</td>\n",
              "      <td>1070.01</td>\n",
              "      <td>603.051</td>\n",
              "      <td>1004.55</td>\n",
              "      <td>591.008</td>\n",
              "      <td>1078.24</td>\n",
              "      <td>692.812</td>\n",
              "      <td>1011.41</td>\n",
              "      <td>691.53</td>\n",
              "      <td>1127.77</td>\n",
              "      <td>781.845</td>\n",
              "      <td>1072.88</td>\n",
              "      <td>774.889</td>\n",
              "      <td>1008.92</td>\n",
              "      <td>414.647</td>\n",
              "      <td>1034.13</td>\n",
              "      <td>491.002</td>\n",
              "      <td>908.92</td>\n",
              "      <td>486.835</td>\n",
              "      <td>1001.17</td>\n",
              "      <td>485.329</td>\n",
              "      <td>1013.81</td>\n",
              "      <td>543.464</td>\n",
              "      <td>1104.62</td>\n",
              "      <td>799.889</td>\n",
              "      <td>1051.54</td>\n",
              "      <td>791.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>714-3-5-35-Z94_B-0000027.jpg</td>\n",
              "      <td>1107.97</td>\n",
              "      <td>532.353</td>\n",
              "      <td>1137.05</td>\n",
              "      <td>536.849</td>\n",
              "      <td>1110.8</td>\n",
              "      <td>540.34</td>\n",
              "      <td>1130.2</td>\n",
              "      <td>531.808</td>\n",
              "      <td>1081.09</td>\n",
              "      <td>534.971</td>\n",
              "      <td>1148.99</td>\n",
              "      <td>561.562</td>\n",
              "      <td>1010.54</td>\n",
              "      <td>560.532</td>\n",
              "      <td>1204.06</td>\n",
              "      <td>625.179</td>\n",
              "      <td>978.218</td>\n",
              "      <td>625.658</td>\n",
              "      <td>1210.03</td>\n",
              "      <td>698.744</td>\n",
              "      <td>974.863</td>\n",
              "      <td>717.147</td>\n",
              "      <td>1066.22</td>\n",
              "      <td>631.881</td>\n",
              "      <td>986.207</td>\n",
              "      <td>616.251</td>\n",
              "      <td>1104.38</td>\n",
              "      <td>698.596</td>\n",
              "      <td>1004.51</td>\n",
              "      <td>718.157</td>\n",
              "      <td>1092.05</td>\n",
              "      <td>769.788</td>\n",
              "      <td>998.965</td>\n",
              "      <td>791.517</td>\n",
              "      <td>1107.97</td>\n",
              "      <td>539.983</td>\n",
              "      <td>1211.94</td>\n",
              "      <td>699.276</td>\n",
              "      <td>999.188</td>\n",
              "      <td>696.859</td>\n",
              "      <td>1051</td>\n",
              "      <td>544.586</td>\n",
              "      <td>1042.05</td>\n",
              "      <td>579.178</td>\n",
              "      <td>1101.68</td>\n",
              "      <td>765.301</td>\n",
              "      <td>1004.35</td>\n",
              "      <td>781.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>714-3-5-35-Z94_C-0000029.jpg</td>\n",
              "      <td>946.431</td>\n",
              "      <td>326.957</td>\n",
              "      <td>974.698</td>\n",
              "      <td>312.677</td>\n",
              "      <td>948.147</td>\n",
              "      <td>312.053</td>\n",
              "      <td>990.44</td>\n",
              "      <td>314.144</td>\n",
              "      <td>937.994</td>\n",
              "      <td>309.993</td>\n",
              "      <td>1025.28</td>\n",
              "      <td>383.895</td>\n",
              "      <td>885.109</td>\n",
              "      <td>373.13</td>\n",
              "      <td>1068.43</td>\n",
              "      <td>427.614</td>\n",
              "      <td>825.613</td>\n",
              "      <td>408.752</td>\n",
              "      <td>1017.7</td>\n",
              "      <td>397.46</td>\n",
              "      <td>815.901</td>\n",
              "      <td>391.214</td>\n",
              "      <td>988.529</td>\n",
              "      <td>573.648</td>\n",
              "      <td>905.352</td>\n",
              "      <td>559.541</td>\n",
              "      <td>1001.41</td>\n",
              "      <td>724.888</td>\n",
              "      <td>907.012</td>\n",
              "      <td>719.254</td>\n",
              "      <td>1012.01</td>\n",
              "      <td>837.378</td>\n",
              "      <td>931.785</td>\n",
              "      <td>829.856</td>\n",
              "      <td>968.057</td>\n",
              "      <td>349.791</td>\n",
              "      <td>1006.55</td>\n",
              "      <td>390.673</td>\n",
              "      <td>829.637</td>\n",
              "      <td>380.514</td>\n",
              "      <td>944.64</td>\n",
              "      <td>429.971</td>\n",
              "      <td>949.645</td>\n",
              "      <td>498.315</td>\n",
              "      <td>1008</td>\n",
              "      <td>854.285</td>\n",
              "      <td>924.399</td>\n",
              "      <td>845.328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>714-3-5-35-Z94_C-0000001.jpg</td>\n",
              "      <td>946.712</td>\n",
              "      <td>319.096</td>\n",
              "      <td>972.311</td>\n",
              "      <td>304.889</td>\n",
              "      <td>946.329</td>\n",
              "      <td>304.855</td>\n",
              "      <td>987.572</td>\n",
              "      <td>304.898</td>\n",
              "      <td>936.099</td>\n",
              "      <td>301.449</td>\n",
              "      <td>1022.05</td>\n",
              "      <td>372.479</td>\n",
              "      <td>884.142</td>\n",
              "      <td>364.13</td>\n",
              "      <td>1061.51</td>\n",
              "      <td>401.216</td>\n",
              "      <td>820.508</td>\n",
              "      <td>387.435</td>\n",
              "      <td>1007.52</td>\n",
              "      <td>370.881</td>\n",
              "      <td>809.523</td>\n",
              "      <td>367.886</td>\n",
              "      <td>987.392</td>\n",
              "      <td>567.914</td>\n",
              "      <td>906.155</td>\n",
              "      <td>556.71</td>\n",
              "      <td>994.531</td>\n",
              "      <td>725.165</td>\n",
              "      <td>904.043</td>\n",
              "      <td>720.461</td>\n",
              "      <td>996.285</td>\n",
              "      <td>837.667</td>\n",
              "      <td>921.455</td>\n",
              "      <td>830.741</td>\n",
              "      <td>969.145</td>\n",
              "      <td>340.23</td>\n",
              "      <td>998.651</td>\n",
              "      <td>363.263</td>\n",
              "      <td>826.371</td>\n",
              "      <td>356.228</td>\n",
              "      <td>946.88</td>\n",
              "      <td>421.963</td>\n",
              "      <td>952.601</td>\n",
              "      <td>492.803</td>\n",
              "      <td>994.22</td>\n",
              "      <td>855.011</td>\n",
              "      <td>915.667</td>\n",
              "      <td>846.371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>714-3-5-35-Z94_D-0000003.jpg</td>\n",
              "      <td>987.948</td>\n",
              "      <td>374.324</td>\n",
              "      <td>1021.63</td>\n",
              "      <td>364.022</td>\n",
              "      <td>1003.51</td>\n",
              "      <td>365.478</td>\n",
              "      <td>1044.12</td>\n",
              "      <td>376.711</td>\n",
              "      <td>1006.27</td>\n",
              "      <td>376.325</td>\n",
              "      <td>1074.14</td>\n",
              "      <td>446.2</td>\n",
              "      <td>980.947</td>\n",
              "      <td>445.665</td>\n",
              "      <td>1105.34</td>\n",
              "      <td>504.6</td>\n",
              "      <td>946.959</td>\n",
              "      <td>503.09</td>\n",
              "      <td>1051.22</td>\n",
              "      <td>529.687</td>\n",
              "      <td>931.553</td>\n",
              "      <td>535.037</td>\n",
              "      <td>1067.68</td>\n",
              "      <td>603.454</td>\n",
              "      <td>1008.55</td>\n",
              "      <td>594.064</td>\n",
              "      <td>1079</td>\n",
              "      <td>681.799</td>\n",
              "      <td>1021.78</td>\n",
              "      <td>682.886</td>\n",
              "      <td>1126.52</td>\n",
              "      <td>761.475</td>\n",
              "      <td>1082.16</td>\n",
              "      <td>758.062</td>\n",
              "      <td>1010.23</td>\n",
              "      <td>419.34</td>\n",
              "      <td>1022.91</td>\n",
              "      <td>533.377</td>\n",
              "      <td>918.777</td>\n",
              "      <td>534.685</td>\n",
              "      <td>1000.85</td>\n",
              "      <td>486.431</td>\n",
              "      <td>1012.44</td>\n",
              "      <td>544.079</td>\n",
              "      <td>1104.79</td>\n",
              "      <td>773.596</td>\n",
              "      <td>1063.23</td>\n",
              "      <td>767.928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          image   nose_x  ... right_instep_x right_instep_y\n",
              "0  714-3-5-35-Z94_D-0000001.jpg  983.371  ...        1051.54        791.001\n",
              "1  714-3-5-35-Z94_B-0000027.jpg  1107.97  ...        1004.35        781.087\n",
              "2  714-3-5-35-Z94_C-0000029.jpg  946.431  ...        924.399        845.328\n",
              "3  714-3-5-35-Z94_C-0000001.jpg  946.712  ...        915.667        846.371\n",
              "4  714-3-5-35-Z94_D-0000003.jpg  987.948  ...        1063.23        767.928\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Xbc55HiX3G"
      },
      "source": [
        "df.to_csv(f'{prefix_dir}/submission_{model_name}{model_ver}.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBeo-B2iX3G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}